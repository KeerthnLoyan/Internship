{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b758dfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"1.Write a python program to display all the header tags from wikipedia.org.\n",
    "\"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "554242f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=requests.get(\"https://en.wikipedia.org/wiki/Main_Page\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22887396",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26573c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List all the header tags :\n",
      "\n",
      "<h1 class=\"firstHeading mw-first-heading\" id=\"firstHeading\" style=\"display: none\">Main Page</h1>\n",
      "\n",
      "<h1><span class=\"mw-headline\" id=\"Welcome_to_Wikipedia\">Welcome to <a href=\"/wiki/Wikipedia\" title=\"Wikipedia\">Wikipedia</a></span></h1>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-tfa-h2\"><span id=\"From_today.27s_featured_article\"></span><span class=\"mw-headline\" id=\"From_today's_featured_article\">From today's featured article</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-dyk-h2\"><span class=\"mw-headline\" id=\"Did_you_know_...\">Did you know ...</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-itn-h2\"><span class=\"mw-headline\" id=\"In_the_news\">In the news</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-otd-h2\"><span class=\"mw-headline\" id=\"On_this_day\">On this day</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-tfp-h2\"><span id=\"Today.27s_featured_picture\"></span><span class=\"mw-headline\" id=\"Today's_featured_picture\">Today's featured picture</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-other\"><span class=\"mw-headline\" id=\"Other_areas_of_Wikipedia\">Other areas of Wikipedia</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-sister\"><span id=\"Wikipedia.27s_sister_projects\"></span><span class=\"mw-headline\" id=\"Wikipedia's_sister_projects\">Wikipedia's sister projects</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-lang\"><span class=\"mw-headline\" id=\"Wikipedia_languages\">Wikipedia languages</span></h2>\n",
      "\n",
      "<h2>Navigation menu</h2>\n",
      "\n",
      "<h3>\n",
      "<label for=\"searchInput\">Search</label>\n",
      "</h3>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "html = urlopen('https://en.wikipedia.org/wiki/Main_Page')\n",
    "bs = BeautifulSoup(html, \"html.parser\")\n",
    "heading = bs.find_all(['h1', 'h2','h3','h4','h5','h6']) \n",
    "print('List all the header tags :', *heading, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a35a5314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_Name</th>\n",
       "      <th>rating</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.233810743491823</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.155764938056866</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>8.985045459496254</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>8.983847179430256</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>8.94728051844463</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Lawrence of Arabia</td>\n",
       "      <td>8.256673075898174</td>\n",
       "      <td>1962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Jagten</td>\n",
       "      <td>8.255023353128404</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>M - Eine Stadt sucht einen Mörder</td>\n",
       "      <td>8.25469835424237</td>\n",
       "      <td>1931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>8.254118320349573</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Vertigo</td>\n",
       "      <td>8.248225734012632</td>\n",
       "      <td>1958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           movie_Name             rating  year\n",
       "0            The Shawshank Redemption  9.233810743491823  1994\n",
       "1                       The Godfather  9.155764938056866  1972\n",
       "2                     The Dark Knight  8.985045459496254  2008\n",
       "3              The Godfather: Part II  8.983847179430256  1974\n",
       "4                        12 Angry Men   8.94728051844463  1957\n",
       "..                                ...                ...   ...\n",
       "95                 Lawrence of Arabia  8.256673075898174  1962\n",
       "96                             Jagten  8.255023353128404  2012\n",
       "97  M - Eine Stadt sucht einen Mörder   8.25469835424237  1931\n",
       "98                 North by Northwest  8.254118320349573  1959\n",
       "99                            Vertigo  8.248225734012632  1958\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "2.Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release)and make data frame.\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "\"\"\"\n",
    "\n",
    "# Downloading imdb movies's data \n",
    "\n",
    "url = 'http://www.imdb.com/chart/top'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "movies = soup.select('td.titleColumn')\n",
    "crew = [a.attrs.get('title') for a in soup.select('td.titleColumn a')]\n",
    "ratings = [b.attrs.get('data-value')\n",
    "        for b in soup.select('td.posterColumn span[name=ir]')]\n",
    "  \n",
    "# create a empty list for storing\n",
    "# movie information\n",
    "list = []\n",
    " \n",
    "# Iterating over movies to extract\n",
    "# each movie's details\n",
    "for index in range(0, len(movies)):\n",
    "     \n",
    "    # Separating movie into: 'Name',\n",
    "    # 'title', 'year'\n",
    "    movie_string = movies[index].get_text()\n",
    "    movie = (' '.join(movie_string.split()).replace('.', ''))\n",
    "    movie_title = movie[len(str(index))+1:-7]\n",
    "    year = re.search('\\((.*?)\\)', movie_string).group(1)\n",
    "    data = { \"movie_Name\": movie_title,\n",
    "            \"rating\": ratings[index],\n",
    "            \"year\": year,\n",
    "            }\n",
    "    list.append(data)\n",
    " \n",
    "list\n",
    "df = pd.DataFrame(list)\n",
    "df=df.head(100) \n",
    "df\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "968c8b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_Name</th>\n",
       "      <th>rating</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jai Bhim</td>\n",
       "      <td>8.400973638688415</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anbe Sivam</td>\n",
       "      <td>8.39312786791382</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Golmaal</td>\n",
       "      <td>8.39064754039644</td>\n",
       "      <td>1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nayakan</td>\n",
       "      <td>8.38268522503125</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pariyerum Perumal</td>\n",
       "      <td>8.370258808730323</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Masaan</td>\n",
       "      <td>8.009142602144752</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Dil Chahta Hai</td>\n",
       "      <td>8.006228472849582</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Kahaani</td>\n",
       "      <td>8.005849395613</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Maheshinte Prathikaaram</td>\n",
       "      <td>8.005611480732998</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Baahubali 2: The Conclusion</td>\n",
       "      <td>8.003893557735458</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      movie_Name             rating  year\n",
       "0                       Jai Bhim  8.400973638688415  2021\n",
       "1                     Anbe Sivam   8.39312786791382  2003\n",
       "2                        Golmaal   8.39064754039644  1979\n",
       "3                        Nayakan   8.38268522503125  1987\n",
       "4              Pariyerum Perumal  8.370258808730323  2018\n",
       "..                           ...                ...   ...\n",
       "95                        Masaan  8.009142602144752  2015\n",
       "96                Dil Chahta Hai  8.006228472849582  2001\n",
       "97                       Kahaani     8.005849395613  2012\n",
       "98       Maheshinte Prathikaaram  8.005611480732998  2016\n",
       "99   Baahubali 2: The Conclusion  8.003893557735458  2017\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"3.Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release)and make data frame.\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\"\"\"\n",
    "\n",
    "# Downloading imdb movies's data \n",
    "\n",
    "url = 'https://www.imdb.com/india/top-rated-indian-movies/'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "movies = soup.select('td.titleColumn')\n",
    "crew = [a.attrs.get('title') for a in soup.select('td.titleColumn a')]\n",
    "ratings = [b.attrs.get('data-value')\n",
    "        for b in soup.select('td.posterColumn span[name=ir]')]\n",
    "  \n",
    "# create a empty list for storing\n",
    "# movie information\n",
    "list = []\n",
    " \n",
    "# Iterating over movies to extract\n",
    "# each movie's details\n",
    "for index in range(0, len(movies)):\n",
    "     \n",
    "    # Separating movie into: 'Name',\n",
    "    # 'title', 'year'\n",
    "    movie_string = movies[index].get_text()\n",
    "    movie = (' '.join(movie_string.split()).replace('.', ''))\n",
    "    movie_title = movie[len(str(index))+1:-7]\n",
    "    year = re.search('\\((.*?)\\)', movie_string).group(1)\n",
    "    data = { \"movie_Name\": movie_title,\n",
    "            \"rating\": ratings[index],\n",
    "            \"year\": year,\n",
    "            }\n",
    "    list.append(data)\n",
    " \n",
    "\n",
    "list\n",
    "df = pd.DataFrame(list)\n",
    "df=df.head(100) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "31dd2ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Former presidents</th>\n",
       "      <th>Terms of service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Pranab Mukherjee (1935-2020)</td>\n",
       "      <td>25 July, 2012 to 25 July, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Smt Pratibha Devisingh Patil (birth - 1934)</td>\n",
       "      <td>25 July, 2007 to 25 July, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam (1931-2015)</td>\n",
       "      <td>25 July, 2002 to 25 July, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shri K. R. Narayanan (1920 - 2005)</td>\n",
       "      <td>25 July, 1997 to 25 July, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dr Shankar Dayal Sharma (1918-1999)</td>\n",
       "      <td>25 July, 1992 to 25 July, 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Shri R Venkataraman (1910-2009)</td>\n",
       "      <td>25 July, 1987 to 25 July, 1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Giani Zail Singh (1916-1994)</td>\n",
       "      <td>25 July, 1982 to 25 July, 1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy (1913-1996)</td>\n",
       "      <td>25 July, 1977 to 25 July, 1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed (1905-1977)</td>\n",
       "      <td>24 August, 1974 to 11 February, 1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shri Varahagiri Venkata Giri (1894-1980)</td>\n",
       "      <td>3 May, 1969 to 20 July, 1969 and 24 August, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dr. Zakir Husain (1897-1969)</td>\n",
       "      <td>13 May, 1967 to 3 May, 1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan (1888-1975)</td>\n",
       "      <td>13 May, 1962 to 13 May, 1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Rajendra Prasad (1884-1963)</td>\n",
       "      <td>26 January, 1950 to 13 May, 1962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Former presidents  \\\n",
       "0             Shri Pranab Mukherjee (1935-2020)   \n",
       "1   Smt Pratibha Devisingh Patil (birth - 1934)   \n",
       "2            DR. A.P.J. Abdul Kalam (1931-2015)   \n",
       "3            Shri K. R. Narayanan (1920 - 2005)   \n",
       "4           Dr Shankar Dayal Sharma (1918-1999)   \n",
       "5               Shri R Venkataraman (1910-2009)   \n",
       "6                  Giani Zail Singh (1916-1994)   \n",
       "7         Shri Neelam Sanjiva Reddy (1913-1996)   \n",
       "8          Dr. Fakhruddin Ali Ahmed (1905-1977)   \n",
       "9      Shri Varahagiri Venkata Giri (1894-1980)   \n",
       "10                 Dr. Zakir Husain (1897-1969)   \n",
       "11     Dr. Sarvepalli Radhakrishnan (1888-1975)   \n",
       "12             Dr. Rajendra Prasad (1884-1963)    \n",
       "\n",
       "                                     Terms of service  \n",
       "0                     25 July, 2012 to 25 July, 2017   \n",
       "1                     25 July, 2007 to 25 July, 2012   \n",
       "2                     25 July, 2002 to 25 July, 2007   \n",
       "3                     25 July, 1997 to 25 July, 2002   \n",
       "4                     25 July, 1992 to 25 July, 1997   \n",
       "5                     25 July, 1987 to 25 July, 1992   \n",
       "6                     25 July, 1982 to 25 July, 1987   \n",
       "7                     25 July, 1977 to 25 July, 1982   \n",
       "8                24 August, 1974 to 11 February, 1977  \n",
       "9    3 May, 1969 to 20 July, 1969 and 24 August, 1...  \n",
       "10                        13 May, 1967 to 3 May, 1969  \n",
       "11                       13 May, 1962 to 13 May, 1967  \n",
       "12                   26 January, 1950 to 13 May, 1962  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"4.Write s python program to display list of respected former presidents of India(i.e. Name , Term of office) \"\"\"\n",
    "\n",
    "\n",
    "from urllib.request import urlopen\n",
    "\n",
    "html = urlopen('https://presidentofindia.nic.in/former-presidents.htm')\n",
    "bs = BeautifulSoup(html, \"html.parser\")\n",
    "heading = bs.find_all(['h3']) \n",
    "#print('List all the header tags :', *heading, sep='\\n\\n')\n",
    "\n",
    "\n",
    "heading1=[] # Emty list to store the title\n",
    "for i in heading:\n",
    "    heading1.append(i.text.replace(\"<h3>\",''))# More than one then find all\n",
    "heading1\n",
    "\n",
    "\n",
    "terms=[] # Emty list to store the title\n",
    "for i in soup.find_all('div',class_='presidentListing'):\n",
    "    terms.append(i.find_all(\"p\")[0].text.split(\":\")[1])\n",
    "terms\n",
    "\n",
    "df=pd.DataFrame({'Former presidents':heading1,'Terms of service':terms})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98a52388",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teams</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Newzeland</td>\n",
       "      <td>12</td>\n",
       "      <td>1505</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>19</td>\n",
       "      <td>2,353</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>18</td>\n",
       "      <td>1,929</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>22</td>\n",
       "      <td>2,304</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>16</td>\n",
       "      <td>1,635</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>South</td>\n",
       "      <td>19</td>\n",
       "      <td>1,872</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>24</td>\n",
       "      <td>2,275</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>24</td>\n",
       "      <td>2,086</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>West Indis</td>\n",
       "      <td>26</td>\n",
       "      <td>1,885</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>15</td>\n",
       "      <td>986</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Teams Matches Points Ratings\n",
       "0    Newzeland      12   1505     125\n",
       "1      England      19  2,353     124\n",
       "2    Australia      18  1,929     107\n",
       "3        India      22  2,304     105\n",
       "4     Pakistan      16  1,635     102\n",
       "5        South      19  1,872      99\n",
       "6   Bangladesh      24  2,275      95\n",
       "7    Sri Lanka      24  2,086      87\n",
       "8   West Indis      26  1,885      73\n",
       "9  Afghanistan      15    986      66"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "5. Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "b) Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "c) Top 10 ODI bowlers along with the records of their team and rating.\n",
    "https://www.icc-cricket.com/rankings/mens/team-rankings/odi\n",
    "\"\"\"\n",
    "\n",
    "page=requests.get(\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\")\n",
    "\n",
    "page\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "team=[] # Emty list to store the title\n",
    "for i in soup.find_all('td',class_=\"table-body__cell rankings-table__team\"):\n",
    "  team.append(i.text.split()[0])# More than one then find all\n",
    "  \n",
    "    \n",
    "team.insert(0,'Newzeland')\n",
    "team[7]='Sri Lanka'\n",
    "team[8]='West Indis'\n",
    "\n",
    "matches=[] # Emty list to store the title\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "  matches.append(i.text.split()[0])# More than one then find all\n",
    "  \n",
    "match=matches[::2] # Splitting the 2 column by one\n",
    "match.insert(0,'12') # Insertion of one top 1 reord \n",
    "\n",
    "\n",
    "points=matches[-1::-2]#Creating another column on the other hand \n",
    "points.reverse() #to help to sort out order respectively in a descending order\n",
    "points.insert(0,'1505')\n",
    "\n",
    "\n",
    "ratings=[] # Emty list to store the title\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "  ratings.append(i.text)# More than one then find all\n",
    "\n",
    "ratings.insert(0,'125')\n",
    "\n",
    "#print(len(team),len(match),len(points),len(ratings))\n",
    "\n",
    "print(\"Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\")\n",
    "df=pd.DataFrame({'Teams':team,'Matches':match,'Points':points,'Ratings':ratings})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a32db89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI Batsmen along with the records of their team and rating.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>AUS</td>\n",
       "      <td>745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Player Team Ratings\n",
       "0             Babar Azam  PAK     891\n",
       "1            Virat Kohli  IND     811\n",
       "2            Imam-ul-Haq  PAK     795\n",
       "3           Rohit Sharma  IND     791\n",
       "4        Quinton de Kock   SA     789\n",
       "5         Jonny Bairstow  ENG     775\n",
       "6            Ross Taylor   NZ     775\n",
       "7  Rassie van der Dussen   SA     769\n",
       "8           David Warner  AUS     750\n",
       "9            Aaron Finch  AUS     745"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi\")\n",
    "\n",
    "page\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "  \n",
    "\n",
    "player=[] # Emty list to store the title\n",
    "for i in soup.find_all('td',class_='table-body__cell name'):\n",
    "  player.append(i.text.replace('\\n',''))# More than one then find all\n",
    "player.insert(0,'Babar Azam')\n",
    "\n",
    "team=[] # Emty list to store the title\n",
    "for i in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "  team.append(i.text.replace('\\n',''))# More than one then find all\n",
    "\n",
    "team.insert(0,'PAK')\n",
    "\n",
    "rating=[] # Emty list to store the title\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "  rating.append(i.text.replace('\\n',''))# More than one then find all\n",
    "rating.insert(0,'891')\n",
    "print(\"Top 10 ODI Batsmen along with the records of their team and rating.\")\n",
    "df=pd.DataFrame({'Player':player,'Team':team,'Ratings':rating})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "443adcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI bowlers along with the records of their team and rating\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>PAK</td>\n",
       "      <td>671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shakib Al Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player Team Ratings\n",
       "0       Trent Boult   NZ     726\n",
       "1      Chris Woakes  ENG     700\n",
       "2    Josh Hazlewood  AUS     698\n",
       "3        Matt Henry   NZ     683\n",
       "4  Mujeeb Ur Rahman  AFG     681\n",
       "5    Jasprit Bumrah  IND     679\n",
       "6    Shaheen Afridi  PAK     671\n",
       "7      Mehedi Hasan  BAN     661\n",
       "8   Shakib Al Hasan  BAN     657\n",
       "9       Rashid Khan  AFG     650"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player1=[] # Emty list to store the title\n",
    "for i in soup.find_all('td',class_='table-body__cell name'):\n",
    "  player1.append(i.text.replace('\\n',''))# More than one then find all\n",
    "\n",
    "player1.insert(9,'Trent Boult')\n",
    "player1=player1[9:19]\n",
    "\n",
    "team1=[] # Emty list to store the title\n",
    "for i in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "  team1.append(i.text.replace('\\n',''))# More than one then find all\n",
    "\n",
    "team1.insert(9,'NZ')\n",
    "team1=team1[9:19]\n",
    "\n",
    "rating1=[] # Emty list to store the title\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "  rating1.append(i.text.replace('\\n',''))# More than one then find all\n",
    "\n",
    "rating1.insert(9,'726')\n",
    "rating1=rating1[9:19]\n",
    "\n",
    "#print(len(player1),len(team1),len(rating1))\n",
    "\n",
    "print(\"Top 10 ODI bowlers along with the records of their team and rating\")\n",
    "df=pd.DataFrame({'Player':player1,'Team':team1,'Ratings':rating1})\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e43ef48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teams</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>29</td>\n",
       "      <td>4840</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>28</td>\n",
       "      <td>3,504</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>England</td>\n",
       "      <td>30</td>\n",
       "      <td>3,533</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>29</td>\n",
       "      <td>2,878</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>31</td>\n",
       "      <td>3,030</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>28</td>\n",
       "      <td>2,481</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>12</td>\n",
       "      <td>936</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>26</td>\n",
       "      <td>1,752</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>5</td>\n",
       "      <td>240</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>5</td>\n",
       "      <td>233</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Teams Matches Points Ratings\n",
       "0     Australia      29   4840     167\n",
       "1  South Africa      28  3,504     125\n",
       "2       England      30  3,533     118\n",
       "3         India      29  2,878      99\n",
       "4   New Zealand      31  3,030      98\n",
       "5   West Indies      28  2,481      89\n",
       "6    Bangladesh      12    936      78\n",
       "7      Pakistan      26  1,752      67\n",
       "8       Ireland       5    240      48\n",
       "9     Sri Lanka       5    233      47"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" 6. Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "c) Top 10 women’s ODI all-rounder along with the records of their team and rating.\"\"\"\n",
    "\n",
    "page=requests.get(\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\")\n",
    "\n",
    "page\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "\n",
    "team=[] # Emty list to store the title\n",
    "for i in soup.find_all('span',class_=\"u-hide-phablet\"):\n",
    "  team.append(i.text)# More than one then find all\n",
    "del team[11:16]\n",
    "    \n",
    "\n",
    "\n",
    "matches=[] # Emty list to store the title\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "  matches.append(i.text.split()[0])# More than one then find all\n",
    "matches  \n",
    "match=matches[::2]\n",
    "match.insert(0,'29')\n",
    "\n",
    "\n",
    "ratings=[] # Emty list to store the title\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "  ratings.append(i.text)# More than one then find all\n",
    "\n",
    "ratings.insert(0,'167')\n",
    "\n",
    "points=matches[-1::-2]\n",
    "points.reverse()\n",
    "points.insert(0,'4840')\n",
    "\n",
    "\n",
    "#print(len(team),len(match),len(points),len(ratings))\n",
    "\n",
    "print(\"a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\")\n",
    "df=pd.DataFrame({'Teams':team,'Matches':match,'Points':points,'Ratings':ratings})\n",
    "df.head(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "85cbe65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 women’s ODI Batting players along with the records of their team and rating.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rachael Haynes</td>\n",
       "      <td>AUS</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mithali Raj</td>\n",
       "      <td>IND</td>\n",
       "      <td>686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Player Team Ratings\n",
       "0       Alyssa Healy  AUS     785\n",
       "1     Natalie Sciver  ENG     750\n",
       "2        Beth Mooney  AUS     748\n",
       "3    Laura Wolvaardt   SA     722\n",
       "4        Meg Lanning  AUS     710\n",
       "5     Rachael Haynes  AUS     701\n",
       "6        Mithali Raj  IND     686\n",
       "7  Amy Satterthwaite   NZ     681\n",
       "8    Smriti Mandhana  IND     669\n",
       "9     Tammy Beaumont  ENG     659"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi\")\n",
    "\n",
    "page\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "player=[] # Emty list to store the title\n",
    "\n",
    "for i in soup.find_all('td',class_='table-body__cell name'):\n",
    "  player.append(i.text.replace('\\n',''))# More than one then find all\n",
    "player.insert(0,'Alyssa Healy')\n",
    "\n",
    "team=[] # Emty list to store the title\n",
    "for i in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "  team.append(i.text.replace('\\n',''))# More than one then find all\n",
    "\n",
    "team.insert(0,'AUS')\n",
    "\n",
    "rating=[] # Emty list to store the title\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "  rating.append(i.text.replace('\\n',''))# More than one then find all\n",
    "rating.insert(0,'785')\n",
    "\n",
    "#print(len(player),len(team),len(ratings))\n",
    "print(\"Top 10 women’s ODI Batting players along with the records of their team and rating.\")\n",
    "df=pd.DataFrame({'Player':player,'Team':team,'Ratings':rating})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b6dc108a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 women’s ODI all-rounder along with the records of their team and rating\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>WI</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Katherine Brunt</td>\n",
       "      <td>ENG</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jhulan Goswami</td>\n",
       "      <td>IND</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player Team Rating\n",
       "0    Natalie Sciver  ENG    393\n",
       "1      Ellyse Perry  AUS    374\n",
       "2    Marizanne Kapp   SA    359\n",
       "3   Hayley Matthews   WI    338\n",
       "4       Amelia Kerr   NZ    335\n",
       "5  Ashleigh Gardner  AUS    269\n",
       "6     Deepti Sharma  IND    249\n",
       "7     Jess Jonassen  AUS    245\n",
       "8   Katherine Brunt  ENG    221\n",
       "9    Jhulan Goswami  IND    217"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi\")\n",
    "\n",
    "page\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "\n",
    "player=[] # Emty list to store the title\n",
    "for i in soup.find_all('td',class_=\"table-body__cell name\"):\n",
    "  player.append(i.text.replace(\"\\n\",''))# More than one then find all\n",
    "\n",
    "   \n",
    "player=player[18:28]\n",
    "player.insert(0,'Natalie Sciver')\n",
    "\n",
    "\n",
    "\n",
    "team=[] # Emty list to store the title\n",
    "for i in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "  team.append(i.text.replace(\"\\n\",''))# More than one then find all\n",
    "\n",
    "team=team[18:28]\n",
    "team.insert(0,'ENG')\n",
    "\n",
    "rating=[] # Emty list to store the title\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "  rating.append(i.text.replace(\"\\n\",''))# More than one then find all\n",
    "\n",
    "rating=rating[18:28]\n",
    "rating.insert(0,'393')\n",
    "rating\n",
    "\n",
    "print('Top 10 women’s ODI all-rounder along with the records of their team and rating')\n",
    "df=pd.DataFrame({'Player':player,'Team':team,'Rating':rating})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "690fbcb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headlines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top crypto firms go on the hunt for acquisitio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Investment banks pick their top stocks to buy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Indian and Chinese stock markets could grow fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The luna cryptocurrency has been resurrected a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South Korea is betting on the metaverse — and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>With inflation near 40-year highs, one fund ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Unilever adds billionaire activist investor Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UK launches new visa for world's top graduates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Families will skip meals to deal with the cost...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Asia-Pacific stocks mixed; data shows China's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>'Buy this dip': Wall Street banks name global ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What's next for the 'Metaverse'?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Chelsea takeover: Todd Boehly completes £4.25b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dutch DSM and Swiss Firmenich join forces in c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>There's a 'massive gap' between housing demand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Man in wig throws cake at glass protecting Mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Global recession? Not yet, economists say — bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>China's factory activity falls at slower pace ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Death toll from Brazil floods at least 91, wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Thousands of people are leaving Hong Kong — an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headlines\n",
       "0   Top crypto firms go on the hunt for acquisitio...\n",
       "1   Investment banks pick their top stocks to buy ...\n",
       "2   Indian and Chinese stock markets could grow fo...\n",
       "3   The luna cryptocurrency has been resurrected a...\n",
       "4   South Korea is betting on the metaverse — and ...\n",
       "5   With inflation near 40-year highs, one fund ma...\n",
       "6   Unilever adds billionaire activist investor Ne...\n",
       "7   UK launches new visa for world's top graduates...\n",
       "8   Families will skip meals to deal with the cost...\n",
       "9   Asia-Pacific stocks mixed; data shows China's ...\n",
       "10  'Buy this dip': Wall Street banks name global ...\n",
       "11                   What's next for the 'Metaverse'?\n",
       "12  Chelsea takeover: Todd Boehly completes £4.25b...\n",
       "13  Dutch DSM and Swiss Firmenich join forces in c...\n",
       "14  There's a 'massive gap' between housing demand...\n",
       "15  Man in wig throws cake at glass protecting Mon...\n",
       "16  Global recession? Not yet, economists say — bu...\n",
       "17  China's factory activity falls at slower pace ...\n",
       "18  Death toll from Brazil floods at least 91, wit...\n",
       "19  Thousands of people are leaving Hong Kong — an..."
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" 7.Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world :\n",
    "i) Headline\n",
    "ii) Time\n",
    "iii) News Link\"\"\"\n",
    "\n",
    "# i)Headline \n",
    "\n",
    "page=requests.get('https://www.cnbc.com/world/?region=world')\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "headline=[] # Emty list to store the title\n",
    "for i in soup.find_all('div',class_=\"RiverHeadline-headline RiverHeadline-hasThumbnail\"):\n",
    "  headline.append(i.text)# More than one then find all\n",
    "\n",
    "time=[] # Emty list to store the title\n",
    "for i in soup.find_all('time',class_=\"LatestNews-timestamp\"):\n",
    "  time.append(i.text)# More than one then find all\n",
    "  \n",
    "\n",
    "df=pd.DataFrame({'Headlines':headline })\n",
    "  \n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9b81337a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top crypto firms go on the hunt for acquisitio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Investment banks pick their top stocks to buy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Indian and Chinese stock markets could grow fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The luna cryptocurrency has been resurrected a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South Korea is betting on the metaverse — and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>With inflation near 40-year highs, one fund ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Unilever adds billionaire activist investor Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UK launches new visa for world's top graduates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Families will skip meals to deal with the cost...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Asia-Pacific stocks mixed; data shows China's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>'Buy this dip': Wall Street banks name global ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What's next for the 'Metaverse'?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Chelsea takeover: Todd Boehly completes £4.25b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dutch DSM and Swiss Firmenich join forces in c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>There's a 'massive gap' between housing demand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Man in wig throws cake at glass protecting Mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Global recession? Not yet, economists say — bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>China's factory activity falls at slower pace ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Death toll from Brazil floods at least 91, wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Thousands of people are leaving Hong Kong — an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Time\n",
       "0   Top crypto firms go on the hunt for acquisitio...\n",
       "1   Investment banks pick their top stocks to buy ...\n",
       "2   Indian and Chinese stock markets could grow fo...\n",
       "3   The luna cryptocurrency has been resurrected a...\n",
       "4   South Korea is betting on the metaverse — and ...\n",
       "5   With inflation near 40-year highs, one fund ma...\n",
       "6   Unilever adds billionaire activist investor Ne...\n",
       "7   UK launches new visa for world's top graduates...\n",
       "8   Families will skip meals to deal with the cost...\n",
       "9   Asia-Pacific stocks mixed; data shows China's ...\n",
       "10  'Buy this dip': Wall Street banks name global ...\n",
       "11                   What's next for the 'Metaverse'?\n",
       "12  Chelsea takeover: Todd Boehly completes £4.25b...\n",
       "13  Dutch DSM and Swiss Firmenich join forces in c...\n",
       "14  There's a 'massive gap' between housing demand...\n",
       "15  Man in wig throws cake at glass protecting Mon...\n",
       "16  Global recession? Not yet, economists say — bu...\n",
       "17  China's factory activity falls at slower pace ...\n",
       "18  Death toll from Brazil floods at least 91, wit...\n",
       "19  Thousands of people are leaving Hong Kong — an..."
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.Time\n",
    "time=[] # Emty list to store the title\n",
    "for i in soup.find_all('div',class_=\"RiverHeadline-headline RiverHeadline-hasThumbnail\"):\n",
    "  time.append(i.text)# More than one then find all\n",
    "\n",
    "  \n",
    "\n",
    "df=pd.DataFrame({'Time':time })\n",
    "  \n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5cf3e969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Newsl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>French journalist killed in Ukraine; Turkish p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Buy this dip': Wall Street banks name global ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UK launches new visa for world's top graduates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Egypt set for world's sixth largest high-speed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>German inflation at highest level in nearly ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Goldman names its top tech giants to weather v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chelsea takeover: Todd Boehly completes £4.25b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Thousands of people are leaving Hong Kong — an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Paramount's 'Top Gun: Maverick' grosses $124 m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alibaba, Tencent and JD.com all just posted th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Top recruitment and tech execs give their tips...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>How to protect yourself against monkeypox and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What's next for the 'Metaverse'?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Global recession? Not yet, economists say — bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Beijing, Shanghai start to reopen as Covid cas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>South Korea is betting on the metaverse — and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>There's a 'massive gap' between housing demand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Some investors got rich before a popular stabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Stocks could build on gains in the week ahead ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Netflix's fall from grace has media investors ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Newsl\n",
       "0   French journalist killed in Ukraine; Turkish p...\n",
       "1   'Buy this dip': Wall Street banks name global ...\n",
       "2   UK launches new visa for world's top graduates...\n",
       "3   Egypt set for world's sixth largest high-speed...\n",
       "4   German inflation at highest level in nearly ha...\n",
       "5   Goldman names its top tech giants to weather v...\n",
       "6   Chelsea takeover: Todd Boehly completes £4.25b...\n",
       "7   Thousands of people are leaving Hong Kong — an...\n",
       "8   Paramount's 'Top Gun: Maverick' grosses $124 m...\n",
       "9   Alibaba, Tencent and JD.com all just posted th...\n",
       "10  Top recruitment and tech execs give their tips...\n",
       "11  How to protect yourself against monkeypox and ...\n",
       "12                   What's next for the 'Metaverse'?\n",
       "13  Global recession? Not yet, economists say — bu...\n",
       "14  Beijing, Shanghai start to reopen as Covid cas...\n",
       "15  South Korea is betting on the metaverse — and ...\n",
       "16  There's a 'massive gap' between housing demand...\n",
       "17  Some investors got rich before a popular stabl...\n",
       "18  Stocks could build on gains in the week ahead ...\n",
       "19  Netflix's fall from grace has media investors ..."
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.News Link\n",
    "\n",
    "\n",
    "newslink=[] # Emty list to store the title\n",
    "for i in soup.find_all('div',class_=\"RiverHeadline-headline RiverHeadline-hasThumbnail\"):\n",
    "  newslink.append(i.text)# More than one then find all\n",
    "\n",
    "  \n",
    "\n",
    "df=pd.DataFrame({'Newsl':headline })\n",
    "  \n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e3b5e5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Making sense of sensory input</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Paper Title\n",
       "0                                    Reward is enough\n",
       "1                           Making sense of raw input\n",
       "2   Law and logic: A review from an argumentation ...\n",
       "3              Creativity and artificial intelligence\n",
       "4   Artificial cognition for social human–robot in...\n",
       "5   Explanation in artificial intelligence: Insigh...\n",
       "6                       Making sense of sensory input\n",
       "7   Conflict-based search for optimal multi-agent ...\n",
       "8   Between MDPs and semi-MDPs: A framework for te...\n",
       "9   The Hanabi challenge: A new frontier for AI re...\n",
       "10  Evaluating XAI: A comparison of rule-based and...\n",
       "11           Argumentation in artificial intelligence\n",
       "12  Algorithms for computing strategies in two-pla...\n",
       "13      Multiple object tracking: A literature review\n",
       "14  Selection of relevant features and examples in...\n",
       "15  A survey of inverse reinforcement learning: Ch...\n",
       "16  Explaining individual predictions when feature...\n",
       "17  A review of possible effects of cognitive bias...\n",
       "18  Integrating social power into the decision-mak...\n",
       "19  “That's (not) the output I expected!” On the r...\n",
       "20  Explaining black-box classifiers using post-ho...\n",
       "21  Algorithm runtime prediction: Methods & evalua...\n",
       "22              Wrappers for feature subset selection\n",
       "23  Commonsense visual sensemaking for autonomous ...\n",
       "24         Quantum computation, quantum theory and AI"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" 8) Write a python program to scrape the details of most downloaded articles from AI in last 90 days.\n",
    "https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "Scrape below mentioned details :\n",
    "i) Paper Title\n",
    "ii) Authors\n",
    "iii) Published Date\n",
    "iv) Paper Link\"\"\"\n",
    "\n",
    "#i) Paper Title\n",
    "page=requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "papertitle=[] # Emty list to store the title\n",
    "for i in soup.find_all('h2',class_=\"sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR\"):\n",
    "  papertitle.append(i.text)# More than one then find all\n",
    "\n",
    "  \n",
    "\n",
    "df=pd.DataFrame({'Paper Title':papertitle})\n",
    "  \n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b2277f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Miller, Tim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Authors\n",
       "0   Silver, David, Singh, Satinder, Precup, Doina,...\n",
       "1           Evans, Richard, Bošnjak, Matko and 5 more\n",
       "2                   Prakken, Henry, Sartor, Giovanni \n",
       "3                                 Boden, Margaret A. \n",
       "4     Lemaignan, Séverin, Warnier, Mathieu and 3 more\n",
       "5                                        Miller, Tim \n",
       "6   Evans, Richard, Hernández-Orallo, José and 3 more\n",
       "7   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...\n",
       "8   Sutton, Richard S., Precup, Doina, Singh, Sati...\n",
       "9         Bard, Nolan, Foerster, Jakob N. and 13 more\n",
       "10  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...\n",
       "11               Bench-Capon, T.J.M., Dunne, Paul E. \n",
       "12       Bošanský, Branislav, Lisý, Viliam and 3 more\n",
       "13             Luo, Wenhan, Xing, Junliang and 4 more\n",
       "14                      Blum, Avrim L., Langley, Pat \n",
       "15                   Arora, Saurabh, Doshi, Prashant \n",
       "16      Aas, Kjersti, Jullum, Martin, Løland, Anders \n",
       "17  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...\n",
       "18    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A. \n",
       "19                      Riveiro, Maria, Thill, Serge \n",
       "20  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...\n",
       "21  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...\n",
       "22                      Kohavi, Ron, John, George H. \n",
       "23  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...\n",
       "24                                   Ying, Mingsheng "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Authors\n",
    "author=[] # Emty list to store the title\n",
    "for i in soup.find_all('span',class_=\"sc-1w3fpd7-0 pgLAT\"):\n",
    "  author.append(i.text)# More than one then find all\n",
    "\n",
    "  \n",
    "\n",
    "df=pd.DataFrame({'Authors':author})\n",
    "  \n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c12097d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Published Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>October 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>October 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>October 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>August 1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>June 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>February 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>April 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>February 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>August 1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>March 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>February 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>October 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>August 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>April 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>December 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>August 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>September 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>June 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>December 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>September 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>May 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>January 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>December 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>October 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>February 2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Published Date\n",
       "0     October 2021\n",
       "1     October 2021\n",
       "2     October 2015\n",
       "3      August 1998\n",
       "4        June 2017\n",
       "5    February 2019\n",
       "6       April 2021\n",
       "7    February 2015\n",
       "8      August 1999\n",
       "9       March 2020\n",
       "10   February 2021\n",
       "11    October 2007\n",
       "12     August 2016\n",
       "13      April 2021\n",
       "14   December 1997\n",
       "15     August 2021\n",
       "16  September 2021\n",
       "17       June 2021\n",
       "18   December 2016\n",
       "19  September 2021\n",
       "20        May 2021\n",
       "21    January 2014\n",
       "22   December 1997\n",
       "23    October 2021\n",
       "24   February 2010"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#iii) Published Date\n",
    "\n",
    "date=[] # Emty list to store the title\n",
    "for i in soup.find_all('span',class_=\"sc-1thf9ly-2 bKddwo\"):\n",
    "  date.append(i.text)# More than one then find all\n",
    "\n",
    "  \n",
    "\n",
    "df=pd.DataFrame({'Published Date':date})\n",
    "  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19f340f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enoughSilver, David, Singh, Satinder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making sense of raw inputEvans, Richard, Bošnj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creativity and artificial intelligenceBoden, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Making sense of sensory inputEvans, Richard, H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Argumentation in artificial intelligenceBench-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Multiple object tracking: A literature reviewL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wrappers for feature subset selectionKohavi, R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Quantum computation, quantum theory and AIYing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Paper Link\n",
       "0   Reward is enoughSilver, David, Singh, Satinder...\n",
       "1   Making sense of raw inputEvans, Richard, Bošnj...\n",
       "2   Law and logic: A review from an argumentation ...\n",
       "3   Creativity and artificial intelligenceBoden, M...\n",
       "4   Artificial cognition for social human–robot in...\n",
       "5   Explanation in artificial intelligence: Insigh...\n",
       "6   Making sense of sensory inputEvans, Richard, H...\n",
       "7   Conflict-based search for optimal multi-agent ...\n",
       "8   Between MDPs and semi-MDPs: A framework for te...\n",
       "9   The Hanabi challenge: A new frontier for AI re...\n",
       "10  Evaluating XAI: A comparison of rule-based and...\n",
       "11  Argumentation in artificial intelligenceBench-...\n",
       "12  Algorithms for computing strategies in two-pla...\n",
       "13  Multiple object tracking: A literature reviewL...\n",
       "14  Selection of relevant features and examples in...\n",
       "15  A survey of inverse reinforcement learning: Ch...\n",
       "16  Explaining individual predictions when feature...\n",
       "17  A review of possible effects of cognitive bias...\n",
       "18  Integrating social power into the decision-mak...\n",
       "19  “That's (not) the output I expected!” On the r...\n",
       "20  Explaining black-box classifiers using post-ho...\n",
       "21  Algorithm runtime prediction: Methods & evalua...\n",
       "22  Wrappers for feature subset selectionKohavi, R...\n",
       "23  Commonsense visual sensemaking for autonomous ...\n",
       "24  Quantum computation, quantum theory and AIYing..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#iv) Paper link\n",
    "paperlink=[] # Emty list to store the title\n",
    "for i in soup.find_all('li',class_=\"sc-9zxyh7-1 sc-9zxyh7-2 exAXfr jQmQZp\"):\n",
    "  paperlink.append(i.text)# More than one then find all\n",
    "\n",
    "  \n",
    "\n",
    "df=pd.DataFrame({'Paper Link':paperlink})\n",
    "  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0aaa81f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle BarbequeConnaught Place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree3CS Mall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castle BarbequePacific Mall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cafe KnoshThe Leela Ambience Convention Hotel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque CompanyGardens Galleria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India GrillHilton Garden Inn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi BarbequeTaurus Sarovar Portico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que VillageIndirapuram Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>World CafeVibe by The Lalit Traveller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Indian Grill RoomSuncity Business Tower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mad 4 Bar B QueSector 29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Barbeque 29NIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GlasshouseDoubleTree By Hilton Gurugram Baani ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Restaurant name\n",
       "0                      Castle BarbequeConnaught Place\n",
       "1                             Jungle Jamboree3CS Mall\n",
       "2                         Castle BarbequePacific Mall\n",
       "3       Cafe KnoshThe Leela Ambience Convention Hotel\n",
       "4                The Barbeque CompanyGardens Galleria\n",
       "5                        India GrillHilton Garden Inn\n",
       "6                Delhi BarbequeTaurus Sarovar Portico\n",
       "7   The Monarch - Bar Be Que VillageIndirapuram Ha...\n",
       "8               World CafeVibe by The Lalit Traveller\n",
       "9             Indian Grill RoomSuncity Business Tower\n",
       "10                           Mad 4 Bar B QueSector 29\n",
       "11                                     Barbeque 29NIT\n",
       "12  GlasshouseDoubleTree By Hilton Gurugram Baani ..."
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"9) Write a python program to scrape mentioned details from dineout.co.in :\n",
    "i) Restaurant name\n",
    "ii) Cuisine\n",
    "iii) Location\n",
    "iv) Ratings\n",
    "v) Image URL \"\"\"\n",
    "\n",
    "\n",
    "#i) Restaurant name\n",
    "page=requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "name=[] # Emty list to store the title\n",
    "for i in soup.find_all('div',class_=\"restnt-info cursor\"):\n",
    "  name.append(i.text.split(',')[0])# More than one then find all\n",
    "\n",
    " \n",
    "df=pd.DataFrame({'Restaurant name':name})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6bff2b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dineout Pay Pure Veg 5 Star Buffet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>North IndianItalianChineseAsian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Buffet Casual Dining Best Buffet BBQ Special</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Air Conditioned Cards Accepted Parking Wallet ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Cuisine\n",
       "0                                                   \n",
       "1                Dineout Pay Pure Veg 5 Star Buffet \n",
       "2                    North IndianItalianChineseAsian\n",
       "3      Buffet Casual Dining Best Buffet BBQ Special \n",
       "4  Air Conditioned Cards Accepted Parking Wallet ..."
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ii) Cuisine\n",
    "\n",
    "page=requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "Cuisine=[] # Emty list to store the title\n",
    "for i in soup.find_all('ul',class_=\"options\"):\n",
    "  Cuisine.append(i.text)# More than one then find all\n",
    "\n",
    "Cuisine\n",
    " \n",
    "df=pd.DataFrame({'Cuisine':Cuisine})\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d6da8571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vibe by The Lalit Traveller,Sector 35, Faridabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sector 29, Faridabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NIT, Faridabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DoubleTree By Hilton Gurugram Baani Square,Sec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Location\n",
       "0                      Connaught Place, Central Delhi\n",
       "1              3CS Mall,Lajpat Nagar - 3, South Delhi\n",
       "2              Pacific Mall,Tagore Garden, West Delhi\n",
       "3   The Leela Ambience Convention Hotel,Shahdara, ...\n",
       "4                  Gardens Galleria,Sector 38A, Noida\n",
       "5                Hilton Garden Inn,Saket, South Delhi\n",
       "6      Taurus Sarovar Portico,Mahipalpur, South Delhi\n",
       "7   Indirapuram Habitat Centre,Indirapuram, Ghaziabad\n",
       "8    Vibe by The Lalit Traveller,Sector 35, Faridabad\n",
       "9    Suncity Business Tower,Golf Course Road, Gurgaon\n",
       "10                               Sector 29, Faridabad\n",
       "11                                     NIT, Faridabad\n",
       "12  DoubleTree By Hilton Gurugram Baani Square,Sec..."
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Location\n",
    "location=[] # Emty list to store the title\n",
    "for i in soup.find_all('div',class_=\"restnt-loc ellipsis\"):\n",
    "  location.append(i.text)# More than one then find all\n",
    "\n",
    "location\n",
    "df=pd.DataFrame({'Location':location})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "870212f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating\n",
       "0     3.5\n",
       "1     3.9\n",
       "2     3.9\n",
       "3     4.3\n",
       "4       4\n",
       "5     3.9\n",
       "6     3.7\n",
       "7     3.8\n",
       "8     4.2\n",
       "9     4.3\n",
       "10    3.6\n",
       "11    4.2\n",
       "12      4"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ratings restnt-rating rating-4 hide\n",
    "\n",
    "rating=[] # Emty list to store the title\n",
    "for i in soup.find_all('div',class_=\"restnt-rating rating-4\"):\n",
    "  rating.append(i.text)# More than one then find all\n",
    "\n",
    "\n",
    "df=pd.DataFrame({'Rating':rating})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a14149c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Image\n",
       "0   https://im1.dineout.co.in/images/uploads/resta...\n",
       "1   https://im1.dineout.co.in/images/uploads/resta...\n",
       "2   https://im1.dineout.co.in/images/uploads/resta...\n",
       "3   https://im1.dineout.co.in/images/uploads/resta...\n",
       "4   https://im1.dineout.co.in/images/uploads/resta...\n",
       "5   https://im1.dineout.co.in/images/uploads/resta...\n",
       "6   https://im1.dineout.co.in/images/uploads/resta...\n",
       "7   https://im1.dineout.co.in/images/uploads/resta...\n",
       "8   https://im1.dineout.co.in/images/uploads/resta...\n",
       "9   https://im1.dineout.co.in/images/uploads/resta...\n",
       "10  https://im1.dineout.co.in/images/uploads/resta...\n",
       "11  https://im1.dineout.co.in/images/uploads/resta...\n",
       "12  https://im1.dineout.co.in/images/uploads/resta..."
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image=[] # Emty list to store the title\n",
    "for i in soup.find_all('img',class_='no-img'): # More than one then find all\n",
    "    image.append(i['data-src'])\n",
    "    \n",
    "df=pd.DataFrame({'Image':image})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3c0de2df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Publication</th>\n",
       "      <th>h5-index</th>\n",
       "      <th>h5-median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Nature</td>\n",
       "      <td>414</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>The New England Journal of Medicine</td>\n",
       "      <td>410</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Science</td>\n",
       "      <td>391</td>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>IEEE/CVF Conference on Computer Vision and Pat...</td>\n",
       "      <td>356</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>The Lancet</td>\n",
       "      <td>345</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.</td>\n",
       "      <td>Frontiers in Immunology</td>\n",
       "      <td>134</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.</td>\n",
       "      <td>Small</td>\n",
       "      <td>134</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.</td>\n",
       "      <td>Nature Immunology</td>\n",
       "      <td>133</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.</td>\n",
       "      <td>JAMA Oncology</td>\n",
       "      <td>133</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.</td>\n",
       "      <td>The Lancet Neurology</td>\n",
       "      <td>133</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                                        Publication h5-index h5-median\n",
       "0     1.                                             Nature      414       607\n",
       "1     2.                The New England Journal of Medicine      410       704\n",
       "2     3.                                            Science      391       564\n",
       "3     4.  IEEE/CVF Conference on Computer Vision and Pat...      356       583\n",
       "4     5.                                         The Lancet      345       600\n",
       "..   ...                                                ...      ...       ...\n",
       "95   96.                            Frontiers in Immunology      134       177\n",
       "96   97.                                              Small      134       173\n",
       "97   98.                                  Nature Immunology      133       210\n",
       "98   99.                                      JAMA Oncology      133       202\n",
       "99  100.                               The Lancet Neurology      133       200\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" 10) Write a python program to scrape the details of top publications from Google Scholar from\n",
    "https://scholar.google.com/citations?view_op=top_venues&hl=en\n",
    "i) Rank\n",
    "ii) Publication\n",
    "iii) h5-index\n",
    " iv) h5-median\"\"\"\n",
    "\n",
    "\n",
    "page=requests.get('https://scholar.google.com/citations?view_op=top_venues&hl=en')\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "rank=[] # Emty list to store the title\n",
    "for i in soup.find_all('td',class_=\"gsc_mvt_p\"):\n",
    "  rank.append(i.text)# More than one then find all\n",
    "\n",
    "\n",
    "publication=[] # Emty list to store the title\n",
    "for i in soup.find_all('td',class_=\"gsc_mvt_t\"):\n",
    "  publication.append(i.text)# More than one then find all\n",
    "\n",
    "  \n",
    "h1=[] # Emty list to store the title\n",
    "for i in soup.find_all('td',class_=\"gsc_mvt_n\"):\n",
    "  h1.append(i.text)# More than one then find all\n",
    "h5=h1[::2]\n",
    "  \n",
    "h6=h1[-1::-2]\n",
    "h6.reverse()\n",
    "\n",
    "\n",
    "df=pd.DataFrame({'Rank':rank,'Publication':publication,'h5-index':h5,'h5-median':h6})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1ebb7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
